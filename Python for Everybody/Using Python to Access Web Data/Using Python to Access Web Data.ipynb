{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data With Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will read through and parse a file with text and numbers. You will extract all the numbers in the file and compute the sum of the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# solution 1\n",
    "import re\n",
    "\n",
    "name = raw_input(\"Enter file:\")\n",
    "hand = open(name, \"r\")\n",
    "read = hand.read()\n",
    "nums = re.findall('[0-9]+', read)\n",
    "nums = [int(i)  for i in nums]\n",
    "total = sum(nums)\n",
    "print total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# more compact solution\n",
    "import re\n",
    "\n",
    "print sum( [int(i) for i in re.findall('[0-9]+', open(raw_input(\"Enter file: \")).read()) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Numbers from HTML using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program will use urllib to read the HTML from the data files below, and parse the data, extracting numbers and compute the sum of the numbers in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from BeautifulSoup import *\n",
    "import re\n",
    "\n",
    "url = raw_input('Enter - ')\n",
    "html = urllib.urlopen(url).read()\n",
    "soup = BeautifulSoup(html)\n",
    "nums = []\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('span')\n",
    "for tag in tags:\n",
    "#Look at the parts of a tag\n",
    "#print 'TAG:',tag, str(tag)\n",
    "   nums = nums + re.findall('[0-9]+', str(tag))\n",
    "nums = [int(i) for i in nums]\n",
    "print sum(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following Links in HTML Using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will write a Python program that expands on http://www.pythonlearn.com/code/urllinks.py. The program will use urllib to read the HTML from the data files below, extract the href= vaues from the anchor tags, scan for a tag that is in a particular position from the top and follow that link, repeat the process a number of times, and report the last name you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from BeautifulSoup import *\n",
    "\n",
    "url = raw_input('Enter - ')\n",
    "count = int(raw_input('Enter count: '))\n",
    "position = int(raw_input('Enter position: '))\n",
    "\n",
    "html = urllib.urlopen(url).read()\n",
    "soup = BeautifulSoup(html)\n",
    "\n",
    "for i in range(count):\n",
    "    tags = soup('a')\n",
    "    tags = list(tags)\n",
    "    url = tags[position-1].get('href', None)\n",
    "    print tags[position-1].contents[0]\n",
    "    html = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data from XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will write a Python program somewhat similar to http://www.pythonlearn.com/code/geoxml.py. The program will prompt for a URL, read the XML data from that URL using urllib and then parse and extract the comment counts from the XML data, compute the sum of the numbers in the file and enter the sum,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "url = raw_input('Enter location: ')\n",
    "uh = urllib.urlopen(url)\n",
    "data = uh.read()\n",
    "print 'Retrieved',len(data),'characters'\n",
    "tree = ET.fromstring(data)\n",
    "\n",
    "counts = tree.findall('.//count')\n",
    "\n",
    "nums = [int(count.text) for count in counts]\n",
    "print \"Count: \", len(counts)\n",
    "print \"Sum: \", sum(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data from JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program will prompt for a URL, read the JSON data from that URL using urllib and then parse and extract the comment counts from the JSON data, compute the sum of the numbers in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "url = raw_input('Enter location: ')\n",
    "uh = urllib.urlopen(url)\n",
    "data = uh.read()\n",
    "print 'Retrieved',len(data),'characters'\n",
    "\n",
    "info = json.loads(data)\n",
    "\n",
    "# print comments\n",
    "\"\"\"\n",
    "for item in info['comments']:\n",
    "    print 'Name', item['name']\n",
    "    print 'count', item['count']\n",
    "\"\"\"\n",
    "print sum(int(item['count']) for item in info['comments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using JSON API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this program you will use a GeoLocation lookup API modelled after the Google API to look up some universities and parse the returned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import json\n",
    "\n",
    "#serviceurl = 'http://maps.googleapis.com/maps/api/geocode/json?'\n",
    "serviceurl = 'http://python-data.dr-chuck.net/geojson?'\n",
    "\n",
    "while True:\n",
    "    address = raw_input('Enter location: ')\n",
    "    if len(address) < 1 : break\n",
    "\n",
    "    url = serviceurl + urllib.urlencode({'sensor':'false', 'address': address})\n",
    "    print 'Retrieving', url\n",
    "    uh = urllib.urlopen(url)\n",
    "    data = uh.read()\n",
    "    print 'Retrieved',len(data),'characters'\n",
    "\n",
    "    try: js = json.loads(str(data))\n",
    "    except: js = None\n",
    "    if 'status' not in js or js['status'] != 'OK':\n",
    "        print '==== Failure To Retrieve ===='\n",
    "        print data\n",
    "        continue\n",
    "\n",
    "    print json.dumps(js, indent=4)\n",
    "\n",
    "    place_id = js['results'][0]['place_id']\n",
    "    print place_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
